{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acdOpzV0lYwO"
      },
      "source": [
        "# Data Preprocessing Assessment\n",
        "\n",
        "### DUE: Tuesday, 11 October 2022, 23:59\n",
        "\n",
        "This Jupyter notebook guides you through crucial steps in data preprocessing, which you will need for your IVDA projects. This includes, inter alia, handling missing values, grouping, mapping, and normalizing data.\n",
        "\n",
        "## Grading Schema: \n",
        "\n",
        "You will be graded by the outcome of your code, not the code (quality) itself. Additionally, your written answers will be graded. Your assigned tasks and questions are highlighted in **bold** for you.\n",
        "\n",
        "*   **For plots:** Remember to add titles, legends, axes descriptions, etc. It is recommended you use the *plotly* library.\n",
        "*   Please answer as concisely as possible while using full sentences\n",
        "*  As every week you can get up to 10 points for this exercise. To be transparent we added the weight of each exercise in percentage. Distribute your time accordingly. \n",
        "* Solutions will be provided after the deadline.\n",
        "\n",
        "We start by importing the neccessary packages. Please do not import additional packages in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j8O2xUbk1JN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD5-yhCJtQw5"
      },
      "source": [
        "Import the data from the github repository stated on the exercise slides. \n",
        "Note that you will want to have the responding student's number as your dataframe's index. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1tPIH6tQw5"
      },
      "outputs": [],
      "source": [
        "# url =''\n",
        "# df = pd.read_csv ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0xZ21iFtQw5"
      },
      "source": [
        "Display the first 5 rows of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGHp8Zt4tQw6"
      },
      "outputs": [],
      "source": [
        "# display first rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aft-VH96tQw6"
      },
      "source": [
        "# Task 1 - Handling duplicates & mapping Data (27.5 %)\n",
        "## Task 1.1 \n",
        "**Make yourself familiar with the data's shape and size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYVxMwD6tQw7"
      },
      "outputs": [],
      "source": [
        "print(\"The dataset contains {} data records and {} features.\".format(df.shape[0], df.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7eRT6vwtQw7"
      },
      "source": [
        "Read through all the tasks in this notebook, and create a list of all the questions in the questionaire which are relevant for your assigned data analysis tasks (link to the questionnaire is on the exercise slides). Note that the answer to each question is stored in a column. In this assessment's context, we refer to those columns as *attributes* or *features*.\n",
        "\n",
        "## Task 1.2\n",
        "**Give basic summary statistics for the questions you've identified as relevant, and state which of these questions has the most missing data. 2.5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD1wUU-BtQw8"
      },
      "outputs": [],
      "source": [
        "# summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzW8IBoMxPkK"
      },
      "outputs": [],
      "source": [
        "# Which question has the most missing data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNMoxRrVtQw8"
      },
      "source": [
        "## Task 1.3\n",
        "When working with data, we should be concerned not just by missing data, but also by duplicated rows. **Now, check your dataset from above for duplicates, and delete all but the first entry.**\n",
        "\n",
        "*Hint: Be aware that the dataset contains duplicate indices. The indices function as a unique student number for every student.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvH5anCLtQw8"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av2vzQFntQw9"
      },
      "source": [
        "**Why can you not simply use `df.drop_duplicates(keep ='first')`? What would happen in this case? (Max. 50 words).** **5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBALYRaJtQw9"
      },
      "outputs": [],
      "source": [
        "print(\"After handling duplicates, the dataset now contains {} data records and {} features.\".format(df.shape[0], df.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5GuWtlDtQw9"
      },
      "source": [
        "## Task 1.4\n",
        "**Create a pie chart visualization describing the ratio of responses from each country in your dataset. For now, do not perform any additional clean-up of your data. 5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mdivCAptQw-"
      },
      "outputs": [],
      "source": [
        "c = list(df[\"Q1\"])\n",
        "def counting_as_dict(c):\n",
        "    ###################################################\n",
        "    ##### YOUR CODE STARTS HERE #######################\n",
        "    ###################################################\n",
        "    pass\n",
        "    ###################################################\n",
        "    ##### YOUR CODE ENDS HERE #########################\n",
        "    ###################################################\n",
        "    \n",
        "    \n",
        "\n",
        "def plot_pie(dictionary):\n",
        "    ###################################################\n",
        "    ##### YOUR CODE STARTS HERE #######################\n",
        "    ###################################################\n",
        "    pass\n",
        "    ###################################################\n",
        "    ##### YOUR CODE ENDS HERE #########################\n",
        "    ###################################################\n",
        "\n",
        "#counting_as_dict(c)\n",
        "#plot_pie(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq-CoiSTtQw-"
      },
      "source": [
        "As you can see, the plot is very cluttered. To reduce this clutter, we could instead create and plot a set of logical groupings-- in the case of our data here, these groupings could be continents. **Try to map the countries to the respective continents using the provided `continent.csv` file, and then plot it again. 5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k7UB7bvtQw-"
      },
      "outputs": [],
      "source": [
        "#url2 = \n",
        "#continents = pd.read_csv ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odVBi9NxtQw-"
      },
      "source": [
        "*Hint: Turn the `continents` dataframe into a dictionary you can use for mapping.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRH80FxEtQw_"
      },
      "outputs": [],
      "source": [
        "# Mapping \n",
        "\n",
        "\n",
        "# Visualization\n",
        "\n",
        "#counting_as_dict()\n",
        "#plot_pie()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Enz1C51tQw_"
      },
      "source": [
        "**Inspect the pie chart and the dataframe: Why do you see some 4-5% missing values? Where does these rows come from? (Max. 50 words).** **5 %**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drgVeSV8_LRm"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "YOUR RESPONSE HERE\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlnbl2XttQw_"
      },
      "source": [
        "**Apply your findings from the question above to further reduce the amount of missing data. Plot the pie chart again. 5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsT7fTFKtQw_"
      },
      "outputs": [],
      "source": [
        "#Further reduce missing data\n",
        "\n",
        "\n",
        "\n",
        "# Map and visualize again\n",
        "\n",
        "#counting_as_dict()\n",
        "#plot_pie()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN1KzaSStQw_"
      },
      "source": [
        "Please note: from the perspective of visuzalization theory, pie charts are not ideal. This is because humans do not do well when asked to estimate quantities within (and across) pie charts with spatial disarray. As Edward Tufte once wrote: \n",
        "\n",
        "    \"... the only worse design than a pie chart is several of them.” \n",
        "    \n",
        "    Tufte. (2015). The visual display of quantitative information (Second edition, ninth printing). Graphics Press.\n",
        "\n",
        "In our context, we use pie charts only for the purpose of visualizing the progress we make in our grouping of the data. Since we do not set out to express some subtle findings to a reader, our use case is sufficiently simple for a pie chart. Do not use pie charts in your upcoming group projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJc9g2h0tQxA"
      },
      "source": [
        "# Task 2 - Handling and treating missing values (35 %)\n",
        "## Task 2.1\n",
        "**Visualize the age of the students in your dataset with an appropriate boxplot and histogram. With regards to the visualizations' treatment of missing data, what issues do you encounter here? 2 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW0fSwfc38U8"
      },
      "outputs": [],
      "source": [
        "# Visualize \n",
        "\n",
        "# What problems do you notice in your visualizations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm5PL5Wf383B"
      },
      "source": [
        "**Now, filter out missing data using `np.isnan()`, and run your visualization code again. 3 %**\n",
        "\n",
        "*Hint: If you are working on your local machine, you might want use `from plotly.offline import plot` together with `plot(fig)`. This creates a locally-stored HTML that is then opened within your web browser.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBq9ZF9xtQxA"
      },
      "outputs": [],
      "source": [
        "# Filter data using np.isnan \n",
        "\n",
        "# Visualize \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voVJf12ztQxA"
      },
      "source": [
        "## Task 2.2\n",
        "Inspect your dataset again. We still have to deal with some missing data!\n",
        " \n",
        "Now you must come up with a strategy to reduce your (reduced) dataset's missing values, so that you can continue your work on a nice, clean dataset.\n",
        "\n",
        "*Hint: In general, there are 3 different ways to handle missing data:* \n",
        "1. *Ignoring on purpose (as we did above)*\n",
        "2. *Deleting entire entries (rows) or features (columns) with missing data, or deleting entire features when missing data reaches a certain threshold (i.e. ignoring them in your analysis)*\n",
        "3. *Imputing missing data with the feature's mean or median, or treat a missing value as seperate category (when the feature is categorical).* \n",
        "\n",
        "*But remember: All of the described ways above are data type- and context-dependent!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuNv2o2HtQxA"
      },
      "source": [
        "## Task 2.2.1\n",
        "**Drop rows where all data is missing. Note that, since our index is the unique student number, we should NOT reset the index here. 5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOJCp-IHtQxA"
      },
      "outputs": [],
      "source": [
        "print(\"The dataset before dropping the rows contains {} data records and {} features.\".format(df.shape[0], df.shape[1]))\n",
        "\n",
        "# drop rows with missing data\n",
        "\n",
        "print(\"The dataset now contains {} data records and {} features.\".format(df.shape[0], df.shape[1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niZ-U2Z_tQxB"
      },
      "source": [
        "## Task 2.2.2\n",
        "This task is about Q7 (Age).\n",
        "\n",
        "**Impute the missing values with the feature mean, and visualize again the age of the students in your dataset with an appropriate boxplot and histogram. 5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we1Z6c-PtQxB",
        "outputId": "e1b031b6-299c-460c-f5d1-ea6aec36e57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data : \n",
            " count    8024.000000\n",
            "mean       23.546735\n",
            "std         5.677028\n",
            "min        18.000000\n",
            "25%        20.000000\n",
            "50%        22.000000\n",
            "75%        24.000000\n",
            "max        70.000000\n",
            "Name: Q7, dtype: float64 \n",
            "\n",
            "Imputed Data : \n",
            " count    8024.000000\n",
            "mean       23.546735\n",
            "std         5.677028\n",
            "min        18.000000\n",
            "25%        20.000000\n",
            "50%        22.000000\n",
            "75%        24.000000\n",
            "max        70.000000\n",
            "Name: Q7, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Data : \\n\", df.Q7.describe(), \"\\n\")\n",
        "\n",
        "\n",
        "# impute missing values\n",
        "print(\"Imputed Data : \\n\", df.Q7.describe())\n",
        "\n",
        "\n",
        "# Visualize \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L72UI6n9tQxB"
      },
      "source": [
        "**Show the graphs with the imputed and ignored datasets in one graph (in total, there should be 2 histograms and 2 boxplots). Model your visualization after the example below, and annotate each approach's mean, so that easy comparison between approaches is possible. 10 %**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OIfjJqYtQxB"
      },
      "source": [
        "![annotation_means_%20ex.png](attachment:annotation_means_%20ex.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laQNzmGBtQxC"
      },
      "outputs": [],
      "source": [
        "# Visualize \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFurwujktQxC"
      },
      "source": [
        "**Shortly describe the graph. What can you infer from it? Do the boxplots and histograms differ? If so, explain why. (Max. 100 words).** **5 %**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVhfnLNj-88a"
      },
      "source": [
        "    YOUR RESPONSE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nhXg3mtQxC"
      },
      "source": [
        "## Task 2.2.3\n",
        "This task is about Q4 (Student Status).\n",
        "\n",
        "**As this is categorical data, you will form a new category for the missing data and name it *'unsanswered'*.\n",
        "Then, create a plot for each age group stated below describing the proportion of students who have attended school full-time and part-time. 5 %**\n",
        "\n",
        "*Age groups are: 18-28 and 29-38 and 39+*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVUmAb0-tQxC"
      },
      "outputs": [],
      "source": [
        "# Form new category named \"unanswered\"\n",
        "\n",
        "# Visualize \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c2vxV8HtQxC"
      },
      "source": [
        "\n",
        "# Task 3 (12.5 %) - Grouping data & colour coding\n",
        "Visualize students' perception of how their workload has changed since in-person classes were cancelled. Group the data depending on whether the student is a full-time or a part-time student. The associated questions in the questionaire are Q17 and Q4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VY4mhJptQxC"
      },
      "outputs": [],
      "source": [
        "# Handling missing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWwc9j6xB1lK"
      },
      "source": [
        "**How are you handling missing data here? Explain your choice. (Max. 50 words)** **2.5 %**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgWEsILmB6Ep"
      },
      "source": [
        "    \n",
        "\n",
        "```\n",
        "# YOUR RESPONSE HERE\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5sFOMKDCGz4"
      },
      "source": [
        "**Use an appropriate stacked bar chart as visualization. Plot it two times, once with a two-sided gradient color scheme in red/green, and the other time using the following colours: https://coolors.co/a4161a-e5383b-ffffff-f5f3f4-b1a7a6. 7.5 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Engt5vCgCGXC"
      },
      "outputs": [],
      "source": [
        "# Visualizations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0twwscG_Ch4X"
      },
      "source": [
        "**Discuss the pros and cons of the second colour scheme, and why it might sometimes not be appropriate to use. (Max. 50 words)**  **2.5 %**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GLfMYz5CPHI"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "YOUR RESPONSE HERE\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLoqIUjxtQxD"
      },
      "source": [
        "# Task 4 (25 %) - Normalizing data & colour coding\n",
        "In this last task, you will build an \"emotional satisfaction score\" (ESS) using the data from Q25. \n",
        "\n",
        "To do this, you will group the data into positive and negative feelings, sum up the relevant features, and then normalize the results to a scale of 0 to 1. Use the value for the given categorical data item in Q25 as a measure of \"emotional intensity\" (i.e. 'Never'= 1 and 'Always'= 5). Our \"emotional satisfaction score\" attempts to balance out positive and negative emotions, and so you will calculate it using the formula: \n",
        "\n",
        "    ESS = (positive emotions score sum) - (negative emotions score sum) \n",
        "\n",
        "Afterwards, use an appropriate colour-coded plot to show differences between Bachelor, Masters, and PhD students, using responses from Q5.\n",
        "\n",
        "**Plot: 20 %**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgQ6K5KjtQxD"
      },
      "outputs": [],
      "source": [
        "print(\"The dataset contains {} data records and {} features.\".format(df.shape[0], df.shape[1]))\n",
        "\n",
        "# Handling missing data\n",
        "\n",
        "print(\"The dataframe after removing rows with NaN value in the specified columns contains {} data records and {} features.\".format(df_work_emotion.shape[0], df_work_emotion.shape[1]))\n",
        "\n",
        "# Summarize specific columns\n",
        "\n",
        "\n",
        "# Normalize new columns\n",
        "\n",
        "\n",
        "# Calculate final emotional satisfaction score\n",
        "\n",
        "\n",
        "# Group by Q5, calculate average \n",
        "\n",
        "\n",
        "# Visualization \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQwBgdAOFERL"
      },
      "source": [
        "**Discuss your results. Is the assumption that \"negative emotions experienced by students are balanced out by positive emotions\" apply to any of the groups? For which group is this the case? How did you treat missing data here? (Max. 100 words)** **5 %**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kglbiRQsFptS"
      },
      "source": [
        "    YOUR RESPONSE HERE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
